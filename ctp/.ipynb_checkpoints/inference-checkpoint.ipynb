{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b813634a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "from metrics import compute_edge_metrics\n",
    "from networkx.drawing.nx_agraph import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caf705",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge -y pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c866084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e34066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "from ctp.inference.build_tree_utils import build_tree_MST_CLE\n",
    "from ctp.utils import get_sentences_results_wordnet_df, print_average_metrics, softmax_temp, str2bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a3fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d43e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_with_oracle(predicted, gold, num_oracle_changes=1):\n",
    "    '''Updates the tree to put the top num_oracle_changes worst nodes into their correct position.\n",
    "    args:\n",
    "        predicted: tree to update.\n",
    "        gold: gold tree.\n",
    "        num_oracle_changes: currently not used.\n",
    "    returns:\n",
    "        oracle_update_edges_not_tree: List of edges by updating node where update gets best f1.\n",
    "        oracle_update_edges_tree: List of edges by updating node where update gets best f1, and then running MST.\n",
    "    '''\n",
    "    def get_f1_fixed_node(predicted, gold, node):\n",
    "        predicted_edges = [edge for edge in predicted.edges() if node not in edge] + [edge for edge in gold.edges() if node in edge]\n",
    "        _, _, f = compute_edge_metrics(predicted_edges=predicted_edges, gold_edges=list(gold.edges()))\n",
    "        return f\n",
    "\n",
    "    assert(num_oracle_changes == 1)\n",
    "    best_f1 = -1\n",
    "    best_fixed_node = None\n",
    "    for node in predicted.nodes():\n",
    "        node_fix_f1 = get_f1_fixed_node(predicted=predicted, gold=gold, node=node)\n",
    "        if node_fix_f1 > best_f1:\n",
    "            best_f1 = node_fix_f1\n",
    "            best_fixed_node = node\n",
    "\n",
    "    predicted.remove_node(best_fixed_node)\n",
    "    for edge in gold.edges():\n",
    "        if best_fixed_node in edge:\n",
    "            predicted.add_edge(edge[0], edge[1], weight=1e9)\n",
    "\n",
    "    oracle_update_edges_not_tree = list(predicted.edges())\n",
    "    oracle_update_edges_tree = list(build_tree_MST_CLE(predicted).edges())\n",
    "    return oracle_update_edges_not_tree, oracle_update_edges_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef60522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def draw_trees(gold_tree, predicted_graph, predicted_tree, tree_id):\n",
    "    '''Draws the gold and predicted tree.\n",
    "    args:\n",
    "        gold_tree: The gold tree.\n",
    "        predicted_graph: The predicted graph.\n",
    "        predicted_tree: The predicted tree (the predicted tree after MST).\n",
    "        tree_id: The id of the tree (used in the saved file).\n",
    "    '''\n",
    "    precision, recall, f1 = compute_edge_metrics(list(predicted_graph.edges()), list(gold_tree.edges()))\n",
    "    tree_precision, tree_recall, tree_f1 = compute_edge_metrics(list(predicted_tree.edges()), list(gold_tree.edges()))\n",
    "    try:\n",
    "        root = list(nx.topological_sort(gold_tree))[0]\n",
    "    except Exception:\n",
    "        root = f\"CYCLE_{tree_id}\"\n",
    "\n",
    "    def draw_tree(G, G_invisible, save_name):\n",
    "        '''Draws the graph G.\n",
    "        Position according to G_invisible (not sure if this is why we used G_invisible?).\n",
    "        '''\n",
    "        nx.draw(G_invisible, pos, alpha=0)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=5)\n",
    "        nx.draw(G, pos, node_color=\"#ffffff\")\n",
    "        plt.savefig(os.path.join(experiment_savedir, f\"{save_name}\"), dpi=400)\n",
    "        plt.close()\n",
    "\n",
    "    node_name_mapping = {node: node.replace('_$_', '_') for node in gold_tree.nodes()}  # Having $ in the node names causes problems with plotting the graph.\n",
    "    gold_tree = nx.relabel_nodes(gold_tree, node_name_mapping)\n",
    "    pos = graphviz_layout(gold_tree, prog=\"dot\")\n",
    "    predicted_tree = nx.relabel_nodes(predicted_tree, node_name_mapping)\n",
    "    draw_tree(gold_tree, gold_tree, f\"{root}_{tree_id}_gold\")\n",
    "    draw_tree(predicted_tree, gold_tree, f'{root}_{tree_id}_pruned_f{str(round(tree_f1, 2)).replace(\".\", \"_\")}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa9c1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_wordnet_data(wordnet_df, tree_id, sentences, results, substring_addition=0):\n",
    "    def build_graph(df):\n",
    "        '''Build a graph given the relations in df (a pandas dataframe).'''\n",
    "        G = nx.DiGraph()\n",
    "        for idx, row in df.iterrows():\n",
    "            G.add_edge(row[\"hypernym\"], row[\"term\"])\n",
    "        return G\n",
    "\n",
    "    tree_id_df_subset = wordnet_df[wordnet_df[\"tree_id\"] == tree_id]  # Get the rows of the wordnet_df containing pairs for this subtree.\n",
    "    nodes = list(set(tree_id_df_subset[\"term\"]).union(tree_id_df_subset[\"hypernym\"]))\n",
    "    gold_tree = build_graph(tree_id_df_subset)\n",
    "    predicted_graph = nx.DiGraph()\n",
    "\n",
    "    # Fill the predicted graph edges according to the network's predictions.\n",
    "    for term in nodes:\n",
    "        example_ids_subset = [\n",
    "            example_id\n",
    "            for example_id, sentence_info in sentences.items()\n",
    "            if sentence_info[\"term\"] == ' '.join(term.split('_$_'))\n",
    "        ]\n",
    "        for hypernym in nodes:\n",
    "            if term != hypernym:\n",
    "                pair_example_ids = [\n",
    "                    example_id\n",
    "                    for example_id in example_ids_subset\n",
    "                    if (sentences[example_id][\"hypernym\"] == ' '.join(hypernym.split('_$_')))\n",
    "                ]\n",
    "                # Get the logits corresponding to the network's predictions for this pair (there is one value per pattern).\n",
    "                pair_logit_values_softmax = []\n",
    "                for pair_example_id in pair_example_ids:\n",
    "                    example_prediction = results[pair_example_id]\n",
    "                    logits = [float(logit) for logit in example_prediction[\"logits\"]]\n",
    "                    pattern_logit_values = softmax_temp(np.array(logits))[1]\n",
    "                    # Add the substring addition if the hypernym is a subword of the term.\n",
    "                    if ('_' + hypernym.lower() in term.lower()):\n",
    "                        pattern_logit_values += substring_addition\n",
    "                    pair_logit_values_softmax.append(pattern_logit_values)\n",
    "                weight = np.mean(pair_logit_values_softmax)\n",
    "                predicted_graph.add_edge(hypernym, term, weight=weight)\n",
    "    return gold_tree, predicted_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fda129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_ancestor_graph(G):\n",
    "    '''Converts a (parent) tree to a graph with edges for all ancestor relations in the tree.'''\n",
    "    G_anc = nx.DiGraph()\n",
    "    for node in G.nodes():\n",
    "        for anc in nx.ancestors(G, node):\n",
    "            G_anc.add_edge(anc, node)\n",
    "    return G_anc\n",
    "\n",
    "\n",
    "def get_weighted_average(metrics_list, num_nodes_list):\n",
    "    '''Prints the average metric across subtrees, weighted by the size of each subtree.\n",
    "    args:\n",
    "        metrics_list: A num_subtrees length list of metrics.\n",
    "        num_nodes_list: A num_subtrees length list of the number of nodes per subtree.\n",
    "    '''\n",
    "    print(\n",
    "        f\"{sum(np.array(metrics_list) * np.array(num_nodes_list)) / sum(num_nodes_list):.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8534363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_inference_subtree(tree_id, subtrees_dict, sentences, results, subtrees_info_dict, wordnet_df, prediction_metric_type=\"ancestor\", substring_addition=0, draw_networks=False, num_oracle_changes=0):\n",
    "    '''Computes flattened and structured prediction metrics for network predictions.\n",
    "    args:\n",
    "        tree_id: The id of the subtree for which to run inference.\n",
    "        subtrees_dict: A dictionary containing the gold tree, predicted graph, and predicted tree for each subtree.\n",
    "        subtrees_info_dict: A dictionary containing the metrics for each subtree.\n",
    "        wordnet_df: A dataframe containing parent relations.\n",
    "        prediction_metric_type: \"ancestor\" or \"parent\"; type of metric to predict.\n",
    "        substring_addition: Amount to add to index 1 of logits if the hypernym is a subword of the term.\n",
    "        draw_networks: If true, saves images of the predicted tree, gold tree, and predicted graph.\n",
    "        num_oracle_changes: Number of nodes to move according to the oracle.\n",
    "    '''\n",
    "    gold_tree, predicted_graph = get_wordnet_data(\n",
    "        wordnet_df=wordnet_df,\n",
    "        tree_id=tree_id,\n",
    "        sentences=sentences,\n",
    "        results=results,\n",
    "        substring_addition=substring_addition\n",
    "    )\n",
    "    try:\n",
    "        root_node = list(nx.topological_sort(gold_tree))[0]\n",
    "    except Exception:\n",
    "        root_node = tree_id\n",
    "    predicted_tree = build_tree_MST_CLE(predicted_graph)\n",
    "    if prediction_metric_type == \"ancestor\":\n",
    "        gold_tree_parent = copy.deepcopy(gold_tree)\n",
    "        predicted_tree_parent = copy.deepcopy(predicted_tree)\n",
    "        gold_tree = convert_to_ancestor_graph(gold_tree)\n",
    "        predicted_tree = convert_to_ancestor_graph(predicted_tree)\n",
    "    else:\n",
    "        gold_tree_parent = copy.deepcopy(gold_tree)\n",
    "        predicted_tree_parent = copy.deepcopy(predicted_tree)\n",
    "    precision, recall, f1 = compute_edge_metrics(predicted_edges=list(predicted_tree.edges()),\n",
    "            gold_edges=list(gold_tree.edges()))\n",
    "\n",
    "    subtrees_dict[root_node] = {\n",
    "        \"tree_id\": tree_id,\n",
    "        \"gold\": gold_tree,\n",
    "        \"predicted\": predicted_tree,\n",
    "        \"predicted_graph\": predicted_graph,\n",
    "        \"gold_parent\": gold_tree_parent,\n",
    "        \"predicted_parent\": predicted_tree_parent\n",
    "    }\n",
    "    subtrees_info_dict[root_node] = {\n",
    "        \"tree_id\": tree_id,\n",
    "        \"subtree_size\": len(gold_tree.nodes()),\n",
    "        \"predicted_unpruned_size\": len(predicted_graph.nodes()),\n",
    "        \"predicted_pruned_size\": len(predicted_tree.nodes()),\n",
    "        \"pruned_precision\": precision,\n",
    "        \"pruned_recall\": recall,\n",
    "        \"pruned_f1\": f1,\n",
    "    }\n",
    "    if draw_networks:\n",
    "        draw_trees(gold_tree, predicted_graph, predicted_tree, tree_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff5bcf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arguments(experiment_name='WN_par_bert_1e6_seed2', results_dir='./outputs/results', sentences_dir='./datasets/texeval/generated_training_pairs', wordnet_dir='./datasets/data_creators/df_csvs', prediction_metric_type='parent', softmax_temp=1, draw_networks=True, save_metrics=True, epoch_num=10, substring_addition=0, config_dir='ctp/experiment_configs')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Arguments():\n",
    "    experiment_name:str=\"WN_par_bert_1e6_seed2\"\n",
    "    results_dir:str=\"./outputs/results\"\n",
    "    sentences_dir:str=\"./datasets/texeval/generated_training_pairs\"\n",
    "    wordnet_dir:str=\"./datasets/data_creators/df_csvs\"\n",
    "    prediction_metric_type:str=\"parent\"\n",
    "    softmax_temp:int=1\n",
    "    draw_networks:bool=True\n",
    "    save_metrics:bool=True\n",
    "    epoch_num:int=10\n",
    "    substring_addition:int=0\n",
    "    config_dir:str=\"ctp/experiment_configs\"\n",
    "args = Arguments()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "613e080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/ctp\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a82207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "\n",
    "with open(os.path.join(args.config_dir, args.experiment_name + \".json\")) as results_file:\n",
    "    results_info_config = json.load(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a50b73f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4995ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree(\"outputs/results/WN_par_bert_1e6_seed2_parent_substring_addition_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98034f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r taxos.zip outputs/results/WN_par_bert_1e6_seed2_parent_substring_addition_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c67b841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch num 10: pruned_precision 0.41 // pruned_recall 0.41 // pruned_f1 0.41\n"
     ]
    }
   ],
   "source": [
    "results_filename = results_info_config[\n",
    "    \"results_filename\"\n",
    "].format(epoch_num=args.epoch_num)\n",
    "sentences_filename = results_info_config[\"test_filenames\"]\n",
    "sentences_filename = \"wordnet_bansal_anc_0_sib_0_desc_0_rand_0_parent_1_test_subsample_0_pos_subset_None.json\"\n",
    "wordnet_filename = results_info_config[\"wordnet_filename\"]\n",
    "\n",
    "sentences, results, wordnet_df = get_sentences_results_wordnet_df(\n",
    "        wordnet_filepath=os.path.join(args.wordnet_dir, wordnet_filename),\n",
    "        results_filepath=os.path.join(args.results_dir, results_filename),\n",
    "        sentences_filepath=os.path.join(args.sentences_dir, sentences_filename))\n",
    "\n",
    "sentence_keys = np.array(list(sentences.keys()))\n",
    "tree_ids = np.unique([val[\"tree_id\"] for val in sentences.values()])\n",
    "\n",
    "subtrees_info_dict = {}\n",
    "subtrees_dict = {}\n",
    "experiment_savedir = os.path.join(args.results_dir,\n",
    "    f\"{args.experiment_name}_{args.prediction_metric_type}_substring_addition_{args.substring_addition}/\")\n",
    "if not os.path.exists(experiment_savedir):\n",
    "    os.makedirs(experiment_savedir)\n",
    "\n",
    "# Run inference for each subtree.\n",
    "for tree_id in tree_ids:\n",
    "    run_inference_subtree(\n",
    "        tree_id=tree_id,\n",
    "        prediction_metric_type=args.prediction_metric_type,\n",
    "        sentences=sentences,\n",
    "        results=results,\n",
    "        draw_networks=args.draw_networks,\n",
    "        subtrees_dict=subtrees_dict,\n",
    "        subtrees_info_dict=subtrees_info_dict,\n",
    "        wordnet_df=wordnet_df,\n",
    "    )\n",
    "\n",
    "# Save results.\n",
    "with open(\n",
    "    os.path.join(args.results_dir,\n",
    "        f\"subtrees_{args.experiment_name}_{args.prediction_metric_type}_{args.softmax_temp}_substring_addition_{args.substring_addition}.p\"),\n",
    "    \"wb\",\n",
    ") as f:\n",
    "    pickle.dump(subtrees_dict, f)\n",
    "\n",
    "if args.save_metrics:\n",
    "    with open(\n",
    "        os.path.join(\n",
    "            args.results_dir,\n",
    "            f\"subtrees_metrics_{args.experiment_name}_{args.prediction_metric_type}_{args.softmax_temp}_substring_addition_{args.substring_addition}.json\",\n",
    "        ),\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(subtrees_info_dict, f)\n",
    "\n",
    "# Print average metrics over subtrees.\n",
    "print_average_metrics(subtrees_info_dict, args.epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "073ce61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/ctp'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601cf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
